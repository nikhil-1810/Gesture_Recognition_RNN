{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet\n",
      "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from efficientnet) (0.19.2)\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.8/dist-packages (from efficientnet) (1.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.19.4)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (2.19.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (21.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (2022.5.4)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (2.6.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (9.0.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->scikit-image->efficientnet) (3.0.7)\n",
      "Installing collected packages: efficientnet\n",
      "Successfully installed efficientnet-1.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "#from scipy.misc import imread, imresize\n",
    "#import imread, imresize\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize as imresize\n",
    "import datetime\n",
    "import os\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('datasets/Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('datasets/Project_data/val.csv').readlines())\n",
    "batch_size = 10 #experiment with the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#math.floor(len(train_doc) / batch_size)\n",
    "#round(((len(train_doc) / batch_size)-num_batches*batch_size)\n",
    "#len(train_doc)\n",
    "len(train_doc) % batch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "batch_size = 64 #experiment with the batch size \n",
    "height=128 \n",
    "width=128\n",
    "INPUT_SIZE_IN_BATCH=10\n",
    "INPUT_PER_FOLDER=30\n",
    "y=height\n",
    "z=width\n",
    "# folder_list = train_doc/val_doc\n",
    "def generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = 10 #create a list of image numbers you want to use for a particular video\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = math.floor(len(folder_list) / batch_size) # calculate the number of batches (number of videos / batch size)\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,img_idx,128,128,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            mandatory = [0,1,28,29]\n",
    "            random_list_1 = rn.sample(range(2,28),10 - 4)\n",
    "            random_list_1.extend(mandatory)\n",
    "            random_list_1.sort()\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(random_list_1): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    image = imresize(image, (128,128),anti_aliasing=True)\n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = (image[:,:,0] - np.min(image[:,:,0])) / (np.max(image[:,:,0]) - np.min(image[:,:,0]))#normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,1] = (image[:,:,1] - np.min(image[:,:,1])) / (np.max(image[:,:,1]) - np.min(image[:,:,1]))#normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = (image[:,:,2] - np.min(image[:,:,2])) / (np.max(image[:,:,2]) - np.min(image[:,:,2]))#normalise and feed in the image\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "                #batch_labels[folder, int([folder + (batch*batch_size)].strip().split(';')[2])] = 1                                                                       \n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "        \n",
    "def normalize(imag):    \n",
    "    return (imag[:,:,0]-imag[:,:,0].mean())/imag[:,:,0].std(), (imag[:,:,1]-imag[:,:,1].mean())/imag[:,:,1].std(), (imag[:,:,2]-imag[:,:,2].mean())/imag[:,:,2].std()\n",
    "\n",
    "def cropAndResize(imag,height,width):\n",
    "    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "    # CROPPING (making aspect ratio same)\n",
    "    if abs(imag.shape[0]-imag.shape[1])%2==0 and imag.shape[0]!=imag.shape[1]:\n",
    "        dimension_diff=abs(imag.shape[0]-imag.shape[1])\n",
    "        cropping_ratio=dimension_diff//2\n",
    "        if imag.shape[0]>imag.shape[1]:\n",
    "            imag=imag[cropping_ratio:imag.shape[0]-cropping_ratio,:,:]\n",
    "        elif imag.shape[0]<imag.shape[1]:\n",
    "            imag=imag[:,cropping_ratio:imag.shape[1]-cropping_ratio,:]\n",
    "                    \n",
    "    # RESIZING\n",
    "    if imag.shape[0]>height or imag.shape[1]>width:\n",
    "        imag=imresize(imag,size=(height,width),\n",
    "                      interp='bilinear',mode='RGB')\n",
    "        \n",
    "    return imag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 10\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = 'datasets/Project_data/train'\n",
    "val_path = 'datasets/Project_data/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 10# choose the number of epochs\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "16809984/16804768 [==============================] - 1s 0us/step\n",
      "16818176/16804768 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dropout, TimeDistributed, CuDNNLSTM, Dense\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import efficientnet.tfkeras as efn\n",
    "#write your model here\n",
    "base_model = efn.EfficientNetB0(include_top=False, weights='imagenet',input_shape=(128, 128,3))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(TimeDistributed(model, input_shape=(10,128,128,3)))\n",
    "rnn_model.add(CuDNNLSTM(64,return_sequences=False))\n",
    "rnn_model.add(Dropout(0.5))\n",
    "rnn_model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " stem_conv (Conv2D)             (None, 64, 64, 32)   864         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " stem_bn (BatchNormalization)   (None, 64, 64, 32)   128         ['stem_conv[0][0]']              \n",
      "                                                                                                  \n",
      " stem_activation (Activation)   (None, 64, 64, 32)   0           ['stem_bn[0][0]']                \n",
      "                                                                                                  \n",
      " block1a_dwconv (DepthwiseConv2  (None, 64, 64, 32)  288         ['stem_activation[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block1a_bn (BatchNormalization  (None, 64, 64, 32)  128         ['block1a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block1a_activation (Activation  (None, 64, 64, 32)  0           ['block1a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_se_excite (Multiply)   (None, 64, 64, 32)   0           ['block1a_activation[0][0]',     \n",
      "                                                                  'block1a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_project_conv (Conv2D)  (None, 64, 64, 16)   512         ['block1a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_project_bn (BatchNorma  (None, 64, 64, 16)  64          ['block1a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2a_expand_conv (Conv2D)   (None, 64, 64, 96)   1536        ['block1a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_expand_bn (BatchNormal  (None, 64, 64, 96)  384         ['block2a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block2a_expand_activation (Act  (None, 64, 64, 96)  0           ['block2a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block2a_dwconv (DepthwiseConv2  (None, 32, 32, 96)  864         ['block2a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block2a_bn (BatchNormalization  (None, 32, 32, 96)  384         ['block2a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2a_activation (Activation  (None, 32, 32, 96)  0           ['block2a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_se_excite (Multiply)   (None, 32, 32, 96)   0           ['block2a_activation[0][0]',     \n",
      "                                                                  'block2a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_project_conv (Conv2D)  (None, 32, 32, 24)   2304        ['block2a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_project_bn (BatchNorma  (None, 32, 32, 24)  96          ['block2a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_expand_conv (Conv2D)   (None, 32, 32, 144)  3456        ['block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_expand_bn (BatchNormal  (None, 32, 32, 144)  576        ['block2b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_expand_activation (Act  (None, 32, 32, 144)  0          ['block2b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_dwconv (DepthwiseConv2  (None, 32, 32, 144)  1296       ['block2b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block2b_bn (BatchNormalization  (None, 32, 32, 144)  576        ['block2b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2b_activation (Activation  (None, 32, 32, 144)  0          ['block2b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_se_excite (Multiply)   (None, 32, 32, 144)  0           ['block2b_activation[0][0]',     \n",
      "                                                                  'block2b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_project_conv (Conv2D)  (None, 32, 32, 24)   3456        ['block2b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_project_bn (BatchNorma  (None, 32, 32, 24)  96          ['block2b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_drop (FixedDropout)    (None, 32, 32, 24)   0           ['block2b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_add (Add)              (None, 32, 32, 24)   0           ['block2b_drop[0][0]',           \n",
      "                                                                  'block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_expand_conv (Conv2D)   (None, 32, 32, 144)  3456        ['block2b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3a_expand_bn (BatchNormal  (None, 32, 32, 144)  576        ['block3a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_expand_activation (Act  (None, 32, 32, 144)  0          ['block3a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_dwconv (DepthwiseConv2  (None, 16, 16, 144)  3600       ['block3a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block3a_bn (BatchNormalization  (None, 16, 16, 144)  576        ['block3a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3a_activation (Activation  (None, 16, 16, 144)  0          ['block3a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_se_excite (Multiply)   (None, 16, 16, 144)  0           ['block3a_activation[0][0]',     \n",
      "                                                                  'block3a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_project_conv (Conv2D)  (None, 16, 16, 40)   5760        ['block3a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_project_bn (BatchNorma  (None, 16, 16, 40)  160         ['block3a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_expand_conv (Conv2D)   (None, 16, 16, 240)  9600        ['block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_expand_bn (BatchNormal  (None, 16, 16, 240)  960        ['block3b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3b_expand_activation (Act  (None, 16, 16, 240)  0          ['block3b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3b_dwconv (DepthwiseConv2  (None, 16, 16, 240)  6000       ['block3b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block3b_bn (BatchNormalization  (None, 16, 16, 240)  960        ['block3b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3b_activation (Activation  (None, 16, 16, 240)  0          ['block3b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_se_excite (Multiply)   (None, 16, 16, 240)  0           ['block3b_activation[0][0]',     \n",
      "                                                                  'block3b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_project_conv (Conv2D)  (None, 16, 16, 40)   9600        ['block3b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_project_bn (BatchNorma  (None, 16, 16, 40)  160         ['block3b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_drop (FixedDropout)    (None, 16, 16, 40)   0           ['block3b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_add (Add)              (None, 16, 16, 40)   0           ['block3b_drop[0][0]',           \n",
      "                                                                  'block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_expand_conv (Conv2D)   (None, 16, 16, 240)  9600        ['block3b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4a_expand_bn (BatchNormal  (None, 16, 16, 240)  960        ['block4a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_expand_activation (Act  (None, 16, 16, 240)  0          ['block4a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_dwconv (DepthwiseConv2  (None, 8, 8, 240)   2160        ['block4a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4a_bn (BatchNormalization  (None, 8, 8, 240)   960         ['block4a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4a_activation (Activation  (None, 8, 8, 240)   0           ['block4a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_se_excite (Multiply)   (None, 8, 8, 240)    0           ['block4a_activation[0][0]',     \n",
      "                                                                  'block4a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_conv (Conv2D)  (None, 8, 8, 80)     19200       ['block4a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_bn (BatchNorma  (None, 8, 8, 80)    320         ['block4a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_expand_conv (Conv2D)   (None, 8, 8, 480)    38400       ['block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_expand_bn (BatchNormal  (None, 8, 8, 480)   1920        ['block4b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_expand_activation (Act  (None, 8, 8, 480)   0           ['block4b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_dwconv (DepthwiseConv2  (None, 8, 8, 480)   4320        ['block4b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4b_bn (BatchNormalization  (None, 8, 8, 480)   1920        ['block4b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_activation (Activation  (None, 8, 8, 480)   0           ['block4b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_se_excite (Multiply)   (None, 8, 8, 480)    0           ['block4b_activation[0][0]',     \n",
      "                                                                  'block4b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_conv (Conv2D)  (None, 8, 8, 80)     38400       ['block4b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_bn (BatchNorma  (None, 8, 8, 80)    320         ['block4b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_drop (FixedDropout)    (None, 8, 8, 80)     0           ['block4b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_add (Add)              (None, 8, 8, 80)     0           ['block4b_drop[0][0]',           \n",
      "                                                                  'block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_expand_conv (Conv2D)   (None, 8, 8, 480)    38400       ['block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4c_expand_bn (BatchNormal  (None, 8, 8, 480)   1920        ['block4c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_expand_activation (Act  (None, 8, 8, 480)   0           ['block4c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_dwconv (DepthwiseConv2  (None, 8, 8, 480)   4320        ['block4c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4c_bn (BatchNormalization  (None, 8, 8, 480)   1920        ['block4c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_activation (Activation  (None, 8, 8, 480)   0           ['block4c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_se_excite (Multiply)   (None, 8, 8, 480)    0           ['block4c_activation[0][0]',     \n",
      "                                                                  'block4c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_conv (Conv2D)  (None, 8, 8, 80)     38400       ['block4c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_bn (BatchNorma  (None, 8, 8, 80)    320         ['block4c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4c_drop (FixedDropout)    (None, 8, 8, 80)     0           ['block4c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_add (Add)              (None, 8, 8, 80)     0           ['block4c_drop[0][0]',           \n",
      "                                                                  'block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_conv (Conv2D)   (None, 8, 8, 480)    38400       ['block4c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_bn (BatchNormal  (None, 8, 8, 480)   1920        ['block5a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_expand_activation (Act  (None, 8, 8, 480)   0           ['block5a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_dwconv (DepthwiseConv2  (None, 8, 8, 480)   12000       ['block5a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5a_bn (BatchNormalization  (None, 8, 8, 480)   1920        ['block5a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_activation (Activation  (None, 8, 8, 480)   0           ['block5a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_se_excite (Multiply)   (None, 8, 8, 480)    0           ['block5a_activation[0][0]',     \n",
      "                                                                  'block5a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_conv (Conv2D)  (None, 8, 8, 112)    53760       ['block5a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_bn (BatchNorma  (None, 8, 8, 112)   448         ['block5a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_expand_conv (Conv2D)   (None, 8, 8, 672)    75264       ['block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_expand_bn (BatchNormal  (None, 8, 8, 672)   2688        ['block5b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5b_expand_activation (Act  (None, 8, 8, 672)   0           ['block5b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5b_dwconv (DepthwiseConv2  (None, 8, 8, 672)   16800       ['block5b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5b_bn (BatchNormalization  (None, 8, 8, 672)   2688        ['block5b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5b_activation (Activation  (None, 8, 8, 672)   0           ['block5b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_se_excite (Multiply)   (None, 8, 8, 672)    0           ['block5b_activation[0][0]',     \n",
      "                                                                  'block5b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_conv (Conv2D)  (None, 8, 8, 112)    75264       ['block5b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_bn (BatchNorma  (None, 8, 8, 112)   448         ['block5b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_drop (FixedDropout)    (None, 8, 8, 112)    0           ['block5b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_add (Add)              (None, 8, 8, 112)    0           ['block5b_drop[0][0]',           \n",
      "                                                                  'block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_expand_conv (Conv2D)   (None, 8, 8, 672)    75264       ['block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5c_expand_bn (BatchNormal  (None, 8, 8, 672)   2688        ['block5c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5c_expand_activation (Act  (None, 8, 8, 672)   0           ['block5c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5c_dwconv (DepthwiseConv2  (None, 8, 8, 672)   16800       ['block5c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5c_bn (BatchNormalization  (None, 8, 8, 672)   2688        ['block5c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5c_activation (Activation  (None, 8, 8, 672)   0           ['block5c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_se_excite (Multiply)   (None, 8, 8, 672)    0           ['block5c_activation[0][0]',     \n",
      "                                                                  'block5c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_conv (Conv2D)  (None, 8, 8, 112)    75264       ['block5c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_bn (BatchNorma  (None, 8, 8, 112)   448         ['block5c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5c_drop (FixedDropout)    (None, 8, 8, 112)    0           ['block5c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_add (Add)              (None, 8, 8, 112)    0           ['block5c_drop[0][0]',           \n",
      "                                                                  'block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_conv (Conv2D)   (None, 8, 8, 672)    75264       ['block5c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_bn (BatchNormal  (None, 8, 8, 672)   2688        ['block6a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6a_expand_activation (Act  (None, 8, 8, 672)   0           ['block6a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6a_dwconv (DepthwiseConv2  (None, 4, 4, 672)   16800       ['block6a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6a_bn (BatchNormalization  (None, 4, 4, 672)   2688        ['block6a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_activation (Activation  (None, 4, 4, 672)   0           ['block6a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_se_excite (Multiply)   (None, 4, 4, 672)    0           ['block6a_activation[0][0]',     \n",
      "                                                                  'block6a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_conv (Conv2D)  (None, 4, 4, 192)    129024      ['block6a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_bn (BatchNorma  (None, 4, 4, 192)   768         ['block6a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_expand_conv (Conv2D)   (None, 4, 4, 1152)   221184      ['block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_expand_bn (BatchNormal  (None, 4, 4, 1152)  4608        ['block6b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6b_expand_activation (Act  (None, 4, 4, 1152)  0           ['block6b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6b_dwconv (DepthwiseConv2  (None, 4, 4, 1152)  28800       ['block6b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6b_bn (BatchNormalization  (None, 4, 4, 1152)  4608        ['block6b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6b_activation (Activation  (None, 4, 4, 1152)  0           ['block6b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_se_excite (Multiply)   (None, 4, 4, 1152)   0           ['block6b_activation[0][0]',     \n",
      "                                                                  'block6b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_conv (Conv2D)  (None, 4, 4, 192)    221184      ['block6b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_bn (BatchNorma  (None, 4, 4, 192)   768         ['block6b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_drop (FixedDropout)    (None, 4, 4, 192)    0           ['block6b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_add (Add)              (None, 4, 4, 192)    0           ['block6b_drop[0][0]',           \n",
      "                                                                  'block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_expand_conv (Conv2D)   (None, 4, 4, 1152)   221184      ['block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6c_expand_bn (BatchNormal  (None, 4, 4, 1152)  4608        ['block6c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6c_expand_activation (Act  (None, 4, 4, 1152)  0           ['block6c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6c_dwconv (DepthwiseConv2  (None, 4, 4, 1152)  28800       ['block6c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6c_bn (BatchNormalization  (None, 4, 4, 1152)  4608        ['block6c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6c_activation (Activation  (None, 4, 4, 1152)  0           ['block6c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_se_excite (Multiply)   (None, 4, 4, 1152)   0           ['block6c_activation[0][0]',     \n",
      "                                                                  'block6c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_conv (Conv2D)  (None, 4, 4, 192)    221184      ['block6c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_bn (BatchNorma  (None, 4, 4, 192)   768         ['block6c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6c_drop (FixedDropout)    (None, 4, 4, 192)    0           ['block6c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_add (Add)              (None, 4, 4, 192)    0           ['block6c_drop[0][0]',           \n",
      "                                                                  'block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_conv (Conv2D)   (None, 4, 4, 1152)   221184      ['block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_bn (BatchNormal  (None, 4, 4, 1152)  4608        ['block6d_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6d_expand_activation (Act  (None, 4, 4, 1152)  0           ['block6d_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6d_dwconv (DepthwiseConv2  (None, 4, 4, 1152)  28800       ['block6d_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6d_bn (BatchNormalization  (None, 4, 4, 1152)  4608        ['block6d_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6d_activation (Activation  (None, 4, 4, 1152)  0           ['block6d_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_se_excite (Multiply)   (None, 4, 4, 1152)   0           ['block6d_activation[0][0]',     \n",
      "                                                                  'block6d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_conv (Conv2D)  (None, 4, 4, 192)    221184      ['block6d_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_bn (BatchNorma  (None, 4, 4, 192)   768         ['block6d_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6d_drop (FixedDropout)    (None, 4, 4, 192)    0           ['block6d_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_add (Add)              (None, 4, 4, 192)    0           ['block6d_drop[0][0]',           \n",
      "                                                                  'block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7a_expand_conv (Conv2D)   (None, 4, 4, 1152)   221184      ['block6d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7a_expand_bn (BatchNormal  (None, 4, 4, 1152)  4608        ['block7a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block7a_expand_activation (Act  (None, 4, 4, 1152)  0           ['block7a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block7a_dwconv (DepthwiseConv2  (None, 4, 4, 1152)  10368       ['block7a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block7a_bn (BatchNormalization  (None, 4, 4, 1152)  4608        ['block7a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7a_activation (Activation  (None, 4, 4, 1152)  0           ['block7a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_se_excite (Multiply)   (None, 4, 4, 1152)   0           ['block7a_activation[0][0]',     \n",
      "                                                                  'block7a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_project_conv (Conv2D)  (None, 4, 4, 320)    368640      ['block7a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_project_bn (BatchNorma  (None, 4, 4, 320)   1280        ['block7a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " top_conv (Conv2D)              (None, 4, 4, 1280)   409600      ['block7a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " top_bn (BatchNormalization)    (None, 4, 4, 1280)   5120        ['top_conv[0][0]']               \n",
      "                                                                                                  \n",
      " top_activation (Activation)    (None, 4, 4, 1280)   0           ['top_bn[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 20480)        0           ['top_activation[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,049,564\n",
      "Trainable params: 0\n",
      "Non-trainable params: 4,049,564\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optimiser = Adam(lr=0.001)#write your optimizer\n",
    "rnn_model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'abcd.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, save_best_only=False, save_weights_only=True, mode='auto', save_freq=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.000001) # write the REducelronplateau code here\n",
    "ES = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0, patience=10, verbose=1, mode='auto', baseline=None, restore_best_weights=True)\n",
    "callbacks_list = [checkpoint, LR, ES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_779/2952588884.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  rnn_model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  datasets/Project_data/train ; batch size = 64\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 17:05:55.591021: I tensorflow/stream_executor/cuda/cuda_dnn.cc:377] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 1/11 [=>............................] - ETA: 1:29 - loss: 1.7311 - categorical_accuracy: 0.2031\n",
      "Epoch 00001: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 2/11 [====>.........................] - ETA: 22s - loss: 1.8086 - categorical_accuracy: 0.2188 \n",
      "Epoch 00001: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 3/11 [=======>......................] - ETA: 26s - loss: 1.7155 - categorical_accuracy: 0.2552\n",
      "Epoch 00001: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 4/11 [=========>....................] - ETA: 25s - loss: 1.6426 - categorical_accuracy: 0.2930\n",
      "Epoch 00001: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 5/11 [============>.................] - ETA: 23s - loss: 1.5501 - categorical_accuracy: 0.3531\n",
      "Epoch 00001: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 6/11 [===============>..............] - ETA: 20s - loss: 1.4745 - categorical_accuracy: 0.3906\n",
      "Epoch 00001: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 7/11 [==================>...........] - ETA: 16s - loss: 1.4323 - categorical_accuracy: 0.4062\n",
      "Epoch 00001: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 8/11 [====================>.........] - ETA: 12s - loss: 1.3914 - categorical_accuracy: 0.4277\n",
      "Epoch 00001: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 9/11 [=======================>......] - ETA: 8s - loss: 1.3609 - categorical_accuracy: 0.4497 \n",
      "Epoch 00001: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "10/11 [==========================>...] - ETA: 4s - loss: 1.3389 - categorical_accuracy: 0.4578\n",
      "Epoch 00001: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.2948 - categorical_accuracy: 0.4858Source path =  datasets/Project_data/val ; batch size = 64\n",
      "11/11 [==============================] - 70s 6s/step - loss: 1.2948 - categorical_accuracy: 0.4858 - val_loss: 0.9111 - val_categorical_accuracy: 0.6953 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 1/11 [=>............................] - ETA: 5s - loss: 0.8533 - categorical_accuracy: 0.7031\n",
      "Epoch 00002: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 2/11 [====>.........................] - ETA: 41s - loss: 0.8550 - categorical_accuracy: 0.7266\n",
      "Epoch 00002: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 3/11 [=======>......................] - ETA: 39s - loss: 0.8576 - categorical_accuracy: 0.7292\n",
      "Epoch 00002: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 4/11 [=========>....................] - ETA: 33s - loss: 0.8894 - categorical_accuracy: 0.7109\n",
      "Epoch 00002: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 5/11 [============>.................] - ETA: 27s - loss: 0.9111 - categorical_accuracy: 0.7000\n",
      "Epoch 00002: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 6/11 [===============>..............] - ETA: 23s - loss: 0.9067 - categorical_accuracy: 0.7031\n",
      "Epoch 00002: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 7/11 [==================>...........] - ETA: 18s - loss: 0.8816 - categorical_accuracy: 0.7188\n",
      "Epoch 00002: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 8/11 [====================>.........] - ETA: 13s - loss: 0.8645 - categorical_accuracy: 0.7188\n",
      "Epoch 00002: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 9/11 [=======================>......] - ETA: 9s - loss: 0.8460 - categorical_accuracy: 0.7274 \n",
      "Epoch 00002: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "10/11 [==========================>...] - ETA: 4s - loss: 0.8440 - categorical_accuracy: 0.7266\n",
      "Epoch 00002: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "11/11 [==============================] - 63s 6s/step - loss: 0.8254 - categorical_accuracy: 0.7344 - val_loss: 0.6717 - val_categorical_accuracy: 0.7969 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 1/11 [=>............................] - ETA: 5s - loss: 0.7567 - categorical_accuracy: 0.7812\n",
      "Epoch 00003: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 2/11 [====>.........................] - ETA: 40s - loss: 0.6984 - categorical_accuracy: 0.7969\n",
      "Epoch 00003: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 3/11 [=======>......................] - ETA: 36s - loss: 0.7123 - categorical_accuracy: 0.7917\n",
      "Epoch 00003: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 4/11 [=========>....................] - ETA: 32s - loss: 0.6739 - categorical_accuracy: 0.8086\n",
      "Epoch 00003: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 5/11 [============>.................] - ETA: 27s - loss: 0.6833 - categorical_accuracy: 0.7937\n",
      "Epoch 00003: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 6/11 [===============>..............] - ETA: 22s - loss: 0.6766 - categorical_accuracy: 0.8021\n",
      "Epoch 00003: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 7/11 [==================>...........] - ETA: 18s - loss: 0.6445 - categorical_accuracy: 0.8103\n",
      "Epoch 00003: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 8/11 [====================>.........] - ETA: 13s - loss: 0.6311 - categorical_accuracy: 0.8145\n",
      "Epoch 00003: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 9/11 [=======================>......] - ETA: 9s - loss: 0.6316 - categorical_accuracy: 0.8212 \n",
      "Epoch 00003: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "10/11 [==========================>...] - ETA: 4s - loss: 0.6229 - categorical_accuracy: 0.8219\n",
      "Epoch 00003: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "11/11 [==============================] - 62s 6s/step - loss: 0.6112 - categorical_accuracy: 0.8267 - val_loss: 0.5494 - val_categorical_accuracy: 0.8672 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 1/11 [=>............................] - ETA: 6s - loss: 0.5593 - categorical_accuracy: 0.8594\n",
      "Epoch 00004: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 2/11 [====>.........................] - ETA: 42s - loss: 0.4818 - categorical_accuracy: 0.8750\n",
      "Epoch 00004: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 3/11 [=======>......................] - ETA: 35s - loss: 0.4814 - categorical_accuracy: 0.8906\n",
      "Epoch 00004: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 4/11 [=========>....................] - ETA: 31s - loss: 0.4952 - categorical_accuracy: 0.8867\n",
      "Epoch 00004: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 5/11 [============>.................] - ETA: 27s - loss: 0.4732 - categorical_accuracy: 0.9000\n",
      "Epoch 00004: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 6/11 [===============>..............] - ETA: 22s - loss: 0.4678 - categorical_accuracy: 0.8906\n",
      "Epoch 00004: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 7/11 [==================>...........] - ETA: 18s - loss: 0.4784 - categorical_accuracy: 0.8862\n",
      "Epoch 00004: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 8/11 [====================>.........] - ETA: 13s - loss: 0.4737 - categorical_accuracy: 0.8906\n",
      "Epoch 00004: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 9/11 [=======================>......] - ETA: 9s - loss: 0.4705 - categorical_accuracy: 0.8906 \n",
      "Epoch 00004: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "10/11 [==========================>...] - ETA: 4s - loss: 0.4605 - categorical_accuracy: 0.8922\n",
      "Epoch 00004: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "11/11 [==============================] - 62s 6s/step - loss: 0.4609 - categorical_accuracy: 0.8920 - val_loss: 0.4455 - val_categorical_accuracy: 0.8906 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 1/11 [=>............................] - ETA: 6s - loss: 0.4729 - categorical_accuracy: 0.8750\n",
      "Epoch 00005: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 2/11 [====>.........................] - ETA: 43s - loss: 0.5246 - categorical_accuracy: 0.8438\n",
      "Epoch 00005: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 3/11 [=======>......................] - ETA: 38s - loss: 0.4773 - categorical_accuracy: 0.8802\n",
      "Epoch 00005: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 4/11 [=========>....................] - ETA: 33s - loss: 0.4619 - categorical_accuracy: 0.8906\n",
      "Epoch 00005: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 5/11 [============>.................] - ETA: 28s - loss: 0.4491 - categorical_accuracy: 0.8969\n",
      "Epoch 00005: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 6/11 [===============>..............] - ETA: 23s - loss: 0.4465 - categorical_accuracy: 0.9062\n",
      "Epoch 00005: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 7/11 [==================>...........] - ETA: 18s - loss: 0.4336 - categorical_accuracy: 0.9062\n",
      "Epoch 00005: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 8/11 [====================>.........] - ETA: 13s - loss: 0.4183 - categorical_accuracy: 0.9102\n",
      "Epoch 00005: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 9/11 [=======================>......] - ETA: 9s - loss: 0.4021 - categorical_accuracy: 0.9149 \n",
      "Epoch 00005: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "10/11 [==========================>...] - ETA: 4s - loss: 0.3928 - categorical_accuracy: 0.9187\n",
      "Epoch 00005: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "11/11 [==============================] - 63s 6s/step - loss: 0.3969 - categorical_accuracy: 0.9176 - val_loss: 0.4481 - val_categorical_accuracy: 0.8672 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 1/11 [=>............................] - ETA: 6s - loss: 0.3223 - categorical_accuracy: 0.9062\n",
      "Epoch 00006: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 2/11 [====>.........................] - ETA: 45s - loss: 0.3688 - categorical_accuracy: 0.8828\n",
      "Epoch 00006: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 3/11 [=======>......................] - ETA: 38s - loss: 0.3530 - categorical_accuracy: 0.9062\n",
      "Epoch 00006: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 4/11 [=========>....................] - ETA: 33s - loss: 0.3311 - categorical_accuracy: 0.9180\n",
      "Epoch 00006: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 5/11 [============>.................] - ETA: 29s - loss: 0.3255 - categorical_accuracy: 0.9250\n",
      "Epoch 00006: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 6/11 [===============>..............] - ETA: 23s - loss: 0.3242 - categorical_accuracy: 0.9297\n",
      "Epoch 00006: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 7/11 [==================>...........] - ETA: 19s - loss: 0.3116 - categorical_accuracy: 0.9375\n",
      "Epoch 00006: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 8/11 [====================>.........] - ETA: 14s - loss: 0.3103 - categorical_accuracy: 0.9375\n",
      "Epoch 00006: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 9/11 [=======================>......] - ETA: 9s - loss: 0.3220 - categorical_accuracy: 0.9306 \n",
      "Epoch 00006: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "10/11 [==========================>...] - ETA: 4s - loss: 0.3198 - categorical_accuracy: 0.9281\n",
      "Epoch 00006: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3125 - categorical_accuracy: 0.9290\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "11/11 [==============================] - 64s 6s/step - loss: 0.3125 - categorical_accuracy: 0.9290 - val_loss: 0.4757 - val_categorical_accuracy: 0.8359 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 1/11 [=>............................] - ETA: 6s - loss: 0.2642 - categorical_accuracy: 0.9375\n",
      "Epoch 00007: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 2/11 [====>.........................] - ETA: 39s - loss: 0.2817 - categorical_accuracy: 0.9141\n",
      "Epoch 00007: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 3/11 [=======>......................] - ETA: 34s - loss: 0.2852 - categorical_accuracy: 0.9219\n",
      "Epoch 00007: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 4/11 [=========>....................] - ETA: 30s - loss: 0.2688 - categorical_accuracy: 0.9336\n",
      "Epoch 00007: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 5/11 [============>.................] - ETA: 27s - loss: 0.2582 - categorical_accuracy: 0.9406\n",
      "Epoch 00007: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 6/11 [===============>..............] - ETA: 22s - loss: 0.2638 - categorical_accuracy: 0.9401\n",
      "Epoch 00007: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 7/11 [==================>...........] - ETA: 17s - loss: 0.2576 - categorical_accuracy: 0.9442\n",
      "Epoch 00007: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 8/11 [====================>.........] - ETA: 13s - loss: 0.2566 - categorical_accuracy: 0.9473\n",
      "Epoch 00007: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 9/11 [=======================>......] - ETA: 9s - loss: 0.2552 - categorical_accuracy: 0.9497 \n",
      "Epoch 00007: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "10/11 [==========================>...] - ETA: 4s - loss: 0.2570 - categorical_accuracy: 0.9500\n",
      "Epoch 00007: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "11/11 [==============================] - 61s 6s/step - loss: 0.2612 - categorical_accuracy: 0.9474 - val_loss: 0.3330 - val_categorical_accuracy: 0.8906 - lr: 2.0000e-04\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 1/11 [=>............................] - ETA: 6s - loss: 0.2522 - categorical_accuracy: 0.9531\n",
      "Epoch 00008: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 2/11 [====>.........................] - ETA: 41s - loss: 0.2419 - categorical_accuracy: 0.9609\n",
      "Epoch 00008: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 3/11 [=======>......................] - ETA: 37s - loss: 0.2375 - categorical_accuracy: 0.9635\n",
      "Epoch 00008: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 4/11 [=========>....................] - ETA: 32s - loss: 0.2241 - categorical_accuracy: 0.9688\n",
      "Epoch 00008: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 5/11 [============>.................] - ETA: 27s - loss: 0.2278 - categorical_accuracy: 0.9688\n",
      "Epoch 00008: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 6/11 [===============>..............] - ETA: 23s - loss: 0.2314 - categorical_accuracy: 0.9635\n",
      "Epoch 00008: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 7/11 [==================>...........] - ETA: 19s - loss: 0.2429 - categorical_accuracy: 0.9576\n",
      "Epoch 00008: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 8/11 [====================>.........] - ETA: 14s - loss: 0.2390 - categorical_accuracy: 0.9590\n",
      "Epoch 00008: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 9/11 [=======================>......] - ETA: 9s - loss: 0.2316 - categorical_accuracy: 0.9618 \n",
      "Epoch 00008: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "10/11 [==========================>...] - ETA: 4s - loss: 0.2301 - categorical_accuracy: 0.9625\n",
      "Epoch 00008: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "11/11 [==============================] - 65s 6s/step - loss: 0.2273 - categorical_accuracy: 0.9616 - val_loss: 0.3961 - val_categorical_accuracy: 0.8750 - lr: 2.0000e-04\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 1/11 [=>............................] - ETA: 6s - loss: 0.2165 - categorical_accuracy: 0.9844\n",
      "Epoch 00009: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 2/11 [====>.........................] - ETA: 42s - loss: 0.2394 - categorical_accuracy: 0.9531\n",
      "Epoch 00009: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 3/11 [=======>......................] - ETA: 36s - loss: 0.2219 - categorical_accuracy: 0.9531\n",
      "Epoch 00009: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 4/11 [=========>....................] - ETA: 31s - loss: 0.2207 - categorical_accuracy: 0.9492\n",
      "Epoch 00009: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 5/11 [============>.................] - ETA: 27s - loss: 0.2149 - categorical_accuracy: 0.9531\n",
      "Epoch 00009: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 6/11 [===============>..............] - ETA: 23s - loss: 0.2333 - categorical_accuracy: 0.9453\n",
      "Epoch 00009: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 7/11 [==================>...........] - ETA: 18s - loss: 0.2308 - categorical_accuracy: 0.9487\n",
      "Epoch 00009: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 8/11 [====================>.........] - ETA: 14s - loss: 0.2249 - categorical_accuracy: 0.9512\n",
      "Epoch 00009: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 9/11 [=======================>......] - ETA: 9s - loss: 0.2174 - categorical_accuracy: 0.9566 \n",
      "Epoch 00009: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "10/11 [==========================>...] - ETA: 4s - loss: 0.2167 - categorical_accuracy: 0.9578\n",
      "Epoch 00009: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "11/11 [==============================] - 64s 6s/step - loss: 0.2124 - categorical_accuracy: 0.9588 - val_loss: 0.3180 - val_categorical_accuracy: 0.8906 - lr: 2.0000e-04\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 1/11 [=>............................] - ETA: 6s - loss: 0.2256 - categorical_accuracy: 0.9531\n",
      "Epoch 00010: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 2/11 [====>.........................] - ETA: 42s - loss: 0.2241 - categorical_accuracy: 0.9609\n",
      "Epoch 00010: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 3/11 [=======>......................] - ETA: 39s - loss: 0.1984 - categorical_accuracy: 0.9688\n",
      "Epoch 00010: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 4/11 [=========>....................] - ETA: 33s - loss: 0.2079 - categorical_accuracy: 0.9688\n",
      "Epoch 00010: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 5/11 [============>.................] - ETA: 28s - loss: 0.2042 - categorical_accuracy: 0.9688\n",
      "Epoch 00010: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 6/11 [===============>..............] - ETA: 23s - loss: 0.2077 - categorical_accuracy: 0.9688\n",
      "Epoch 00010: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 7/11 [==================>...........] - ETA: 19s - loss: 0.2060 - categorical_accuracy: 0.9688\n",
      "Epoch 00010: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 8/11 [====================>.........] - ETA: 14s - loss: 0.2104 - categorical_accuracy: 0.9668\n",
      "Epoch 00010: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      " 9/11 [=======================>......] - ETA: 9s - loss: 0.2152 - categorical_accuracy: 0.9601 \n",
      "Epoch 00010: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "10/11 [==========================>...] - ETA: 4s - loss: 0.2145 - categorical_accuracy: 0.9609\n",
      "Epoch 00010: saving model to model_init_2022-11-2317_03_29.990254/abcd.h5\n",
      "11/11 [==============================] - 65s 6s/step - loss: 0.2082 - categorical_accuracy: 0.9631 - val_loss: 0.3129 - val_categorical_accuracy: 0.8828 - lr: 2.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5de80b0e50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
